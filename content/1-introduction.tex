\chapter{Introduction}

Until the early 2000s Unmanned Aerial Vehicles (UAV) have been limited to the defense and military industries, because of the high costs and the complexity of constructing these vehicles. Nevertheless, they have become cheaper and more available in several civil and academic applications over the past decades. They have not just turned more common, but their capabilities have dramatically increased, therefore they are more popular and widely used in applications such as rescue operations~\cite{rescue-operations}, data collection and geophysics exploration~\cite{data-collection}, inspections~\cite{inspection}, and agricultural purposes~\cite{agriculure}.

This expansion required not only technical developments but advancement in traditional navigation methods, where Global Positioning System (GPS) is combined with Inertial Navigation System (INS), creating GPS-INS system~\cite{gps-ins}. The small unmanned aircraft's future impact depends on how well they can navigate in GPS-denied environments such as narrow city corridors or circumstances with GPS disturbance or spoofing.  Inertial measurements by themselves can be used to estimate the position of the aircraft respected to a known initial position, but they will accumulate errors over time, especially with low-cost Inertial Measurement Unit (IMU) sensors. This phenomenon is usually called drift because estimated values drift away from the true values with time.

To give a better estimation of the position in most GPS-free applications exteroceptive sensors are used such as cameras, laser scanners, distance sensors, \etc{} The type of used sensor mostly depends on the kind of vehicle. For example only considering UAVs, a multirotor drone has completely different aircraft dynamics, mission profile, and sensing requirements compared to fixed-wing aircraft. Since fixed-wing aircraft usually fly at high altitudes above the environment with relatively high speeds, distance sensors are ineffective. In this case, the most common approach is using cameras for instance, both~\cite{gps-ins-cam} and~\cite{rel-nav} leverage visual information captured by cameras and integrate this data with measurements from an IMU to estimate the motion of the aircraft. When an algorithm fails to close the navigation loop, particularly in the absence of external absolute positioning references like GPS, it results in the estimates drift, which emerges due to the algorithm's inability to establish consistent and accurate reference points or constraints, thereby leading to unbounded cumulative errors over time.

The measurement fusion and sensor noise filtering can take place in an Extended Kalman Filter (EKF) framework because typically these are nonlinear systems. EKFs can be used on any kind of vehicle including robots~\cite{EKF-Robot}, Unmanned Aerial Systems (UAS)~\cite{EKF-UAS-1, EKF-UAS-2}, \etc{} They can account for both sensor errors and process uncertainty, but it is important to note that these methods only work well when errors remain small, \eg{} when the availability of GPS measurements makes it possible to regularly remove drift errors. When GPS or any other global measurements are unavailable for a longer period, the global position and yaw angle of the aircraft is unobservable, which eventually leads to the divergence of estimates~\cite{unobservable-1, unobservable-2}. In addition, if an EKF receives a global measurement after significant drift errors have accumulated, nonlinearities can complicate the utilization of the measurement, and it could result in large jumps in the estimate, in some cases it can even lead to filter divergence. This is because the local linearization of the measurement equations around the drifted states is applied, which can present incorrect dynamics.

In recent years a new method was proposed called relative navigation~\cite{rel-nav-1, rel-nav-2}, which can handle these observability and consistency problems. With exteroceptive sensors navigation can be performed concerning the surroundings, hence this method can be divided into a relative front-end and a global back-end, the complete architecture is shown in Figure~\ref{fig:real-nav}. 
\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/rel-nav}
    \caption{Block diagram of relative navigation (\cite{rel-nav}: page 2, Figure 2)}\label{fig:real-nav}
\end{figure}
The front end provides an estimation of the state relative to the local environment, while the back end is an optimization algorithm, which uses the calculations of the front end to produce global estimates. Several important observability and computational benefits are obtained by dividing the architecture into a relative front end and a global back end:
\begin{itemize}
    \item 
    The front end calculates the estimate relative to a local frame, where the states can remain observable and the uncertainty can be accurately represented by a Gaussian distribution. This enables the utilization of the computational advantage of an Error-State Kalman Filter (ESKF), which is a better solution, than an ordinary EKF because it calculates the nominal state according to the original non-linear dynamics, therefore the linearization around this state is a better approximation.
    
    \item 
     On the other hand, the back end uses a graph that can effectively represent nonlinearities in heading and can be robustly optimized with additional constraints, such as opportunistic global measurements or place recognition.
\end{itemize}

In this paper, a visual-inertial navigation algorithm will be presented, which is based on~\cite{rel-nav}. The target UAV is a fixed-wing aircraft called Sindy, shown in Figure~\ref{fig:sindy}.
\begin{figure}[!ht]
    \centering
    \includesvg[width=0.8\textwidth]{figures/Sindy}
    \caption{Realistic drawing of Sindy (\cite{sindy-manual}: title page)}\label{fig:sindy}
\end{figure}

\section{Structure of the paper}

To sum up the involved steps during the project, the primary objective was to integrate a visual-inertial ESKF into a simulation that was already available to me. The simulation consisted of a grid of feature points, and the goal was to use an ESKF-based algorithm to estimate the aircraft's state while flying along a predefined trajectory. I followed a gradual approach in the development process, starting with ideal conditions and incrementally introducing more realistic elements to the simulation. These included IMU- and measurement- noises, sensor biases, and pixelization. Firstly, I implemented the previously described filter with known 3-D coordinates of the measured feature points, but later a triangulation method was implemented called Linear Optimal Sine Triangulation (LOST). The next step involved the insertion of the LOST estimates into the ESKF framework. 

The paper is structured as follows: Chapter~\ref{chap:math} provides an introduction to several fundamental mathematical concepts that are crucial for comprehending our approach. In Chapter~\ref{chap:eskf}, the mathematical foundations of the filter are explained, and the steps of the filter are detailed. Chapter~\ref{chap:LOST} focuses on the introduction of the applied triangulation method called LOST.\@ Chapter~\ref{chap:integration} is devoted to introducing the integration issues of ESKF and LOST.\@ Chapter~\ref{chap:dev} presents the estimation results in Matlab/Simulink environment. Finally, Chapter~\ref{chap:conclusion} offers a summary of the work, and highlights certain future development steps.
